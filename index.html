<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Aaryan Kurade | Computer Vision Engineer</title>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500&family=Space+Grotesk:wght@300;500;700&display=swap" rel="stylesheet">

<link rel="stylesheet" href="style.css">
<!-- FontAwesome for Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
</head>
<body>
<div id="canvas-container"></div>
<div class="container">
    <header>
        <div class="reveal-element">
            <!-- 4. Added Hero Badge -->
            <div class="hero-badge">Open to Work: Computer Vision Engineer</div>
            
            <p class="subtitle">01 // Introduction</p>
            <h1>Aaryan Kurade</h1>
            <p style="font-size: 1.5rem; color: var(--text-main);">Building Production CV Systems</p>
        </div>
        
        <!-- 3. Updated Nav with Icons -->
        <nav class="reveal-element">
            <a href="mailto:aaryankurade27@gmail.com" title="Email"><i class="fas fa-envelope"></i></a>
            <a href="https://www.linkedin.com/in/aaryan-kurade" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
            <a href="https://github.com/Aaryan2304" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="https://medium.com/@aaryankurade0101" target="_blank" title="Medium"><i class="fab fa-medium"></i></a>
        </nav>
    </header>

    <!-- 02 // Profile (About) -->
    <section id="about" style="margin-bottom: 8rem;">
        <div class="reveal-element">
            <p class="subtitle">02 // Profile</p>
            <h2>About Me</h2>
            <div class="tech-card about-card tilt-card">
                <p style="font-size: 1.1rem; margin: 0;">
                    Computer Vision Engineer with production experience across detection, segmentation, tracking, and geospatial applications. Built and deployed CV systems using YOLO, RT-DETR, SAM, and tracking algorithms (ByteTrack, DeepSORT) for sports analytics, satellite imagery, and industrial inspection. Extensive data annotation expertise (Roboflow/CVAT/QGIS) across detection, segmentation, and pose estimation tasks. Specialized in model optimization (ONNX, quantization) and scalable deployment (FastAPI + Docker).
                </p>
            </div>
        </div>
    </section>

    <!-- 03 // Career (Experience) -->
    <section id="experience" style="margin-bottom: 8rem;">
        <div class="reveal-element">
            <p class="subtitle">03 // Career</p>
            <h2>Experience</h2>
            <div class="experience-grid">
                <div class="tech-card tilt-card">
                    <div class="experience-header">
                        <div>
                            <h3 class="company-name">Utopia Optovision Pvt. Ltd.</h3>
                            <p style="margin:0.25rem 0 0 0; color: var(--text-muted);">Machine Learning Intern | Pune, India</p>
                        </div>
                        <span class="exp-date">Jan 2024 - Jan 2025</span>
                    </div>
                    <ul class="tech-list">
                        <li>Developed real-time industrial inspection system using YOLOv8 + PaddleOCR pipeline for conveyor belt code extraction, achieving 15% accuracy improvement and 61% CER reduction (18% → 7%)</li>
                        <li>Benchmarked Custom CNNs, R-CNN, and VLMs (QWEN), selecting YOLO+OCR hybrid to meet <100ms latency requirements for manufacturing lines</li>
                        <li>Optimized inference pipelines for resource-constrained CCTV hardware via ONNX export and async processing</li>
                    </ul>
                </div>
                <div class="tech-card tilt-card">
                    <div class="experience-header">
                        <div>
                            <h3 class="company-name">Arakoo.ai</h3>
                            <p style="margin:0.25rem 0 0 0; color: var(--text-muted);">Software Engineer Intern | US - Remote</p>
                        </div>
                        <span class="exp-date">Aug 2025 - Nov 2025</span>
                    </div>
                    <ul class="tech-list">
                        <li>Built real-time ASR pipeline with Voice Activity Detection, reducing false transcription triggers by 40% via adaptive thresholding and signal preprocessing</li>
                        <li>Deployed FastAPI async speaker diarization module handling 50+ concurrent audio streams with non-blocking I/O</li>
                        <li>Implemented prompt caching strategies reducing LLM inference costs by $0.02/minute through context reuse</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- 03 // Featured Projects (Projects) -->
    <section id="projects" style="margin-bottom: 8rem;">
        <div class="reveal-element">
            <p class="subtitle">03 // Portfolio</p>
            <h2>Featured Projects</h2>
            <div class="project-grid">

                <!-- Project 1: Multi-Sport CV -->
                <div class="tech-card project-card tilt-card">
                    <span style="display: inline-block; background: rgba(251, 191, 36, 0.15); border: 1px solid #FBBF24; color: #FBBF24; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; margin-bottom: 1rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em;">In Progress</span>
                    <h3>Multi-Sport CV Analytics</h3>
                    
                    <p>Tracking and analytics pipelines across volleyball, football, and basketball using ByteTrack, RT-DETR, and custom ONNX models with zero-shot team classification.</p>
                    
                    <div class="project-metrics">
                        <div class="metric"><i class="fas fa-bolt"></i> 100 FPS Ball Detection (CPU)</div>
                        <div class="metric"><i class="fas fa-crosshairs"></i> 87.3% MOTA Player Tracking</div>
                        <div class="metric"><i class="fas fa-tachometer-alt"></i> 30-100 FPS Real-Time Inference</div>
                    </div>

                    <div class="tags">
                        <span class="tag">YOLO</span>
                        <span class="tag">ByteTrack</span>
                        <span class="tag">SigLIP</span>
                        <span class="tag">ONNX</span>
                    </div>
                    <a href="https://github.com/Aaryan2304/sports-ai" target="_blank" class="github-icon-link" title="View on GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                </div>
                
                <!-- Project 2: Visual Search -->
                <div class="tech-card project-card tilt-card">
                    <span style="display: inline-block; background: rgba(16, 185, 129, 0.15); border: 1px solid #10B981; color: #10B981; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; margin-bottom: 1rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em;">Production</span>
                    <h3>AI Visual Search Engine</h3>
                    
                    <p>Deployed semantic search for 100K fashion images using CLIP embeddings + FAISS. Optimized for production with GPU acceleration and hardware detection.</p>
                    
                    <!-- NEW METRICS BOX -->
                    <div class="project-metrics">
                        <div class="metric"><i class="fas fa-bolt"></i> < 100ms P95 Latency</div>
                        <div class="metric"><i class="fas fa-memory"></i> 60%+ Memory Efficiency</div>
                        <div class="metric"><i class="fas fa-check-circle"></i> 99%+ Uptime</div>
                    </div>

                    <div class="tags">
                        <span class="tag">Pytorch</span>
                        <span class="tag">CLIP</span>
                        <span class="tag">FAISS</span>
                        <span class="tag">Docker</span>
                    </div>
                    <a href="https://github.com/Aaryan2304/visual-search-engine" target="_blank" class="github-icon-link" title="View on GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                </div>
                
                <!-- Project 3: Geospatial AI -->
                <div class="tech-card project-card tilt-card">
                    <span style="display: inline-block; background: rgba(251, 191, 36, 0.15); border: 1px solid #FBBF24; color: #FBBF24; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; margin-bottom: 1rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em;">In Progress</span>
                    <h3>Geo-Insight Analyzer</h3>
                    
                    <p>Multi-agent GeoAI system for natural language satellite imagery analysis using LangGraph, Moondream VLM, and SAM3 with Google Earth Engine integration.</p>
                    
                    <div class="project-metrics">
                        <div class="metric"><i class="fas fa-robot"></i> Multi-Agent LangGraph</div>
                        <div class="metric"><i class="fas fa-bolt"></i> Target: <5s Latency</div>
                        <div class="metric"><i class="fas fa-database"></i> ChromaDB Vector Search</div>
                    </div>

                    <div class="tags">
                        <span class="tag">LangGraph</span>
                        <span class="tag">VLM</span>
                        <span class="tag">SAM3</span>
                        <span class="tag">GEE</span>
                    </div>
                    <a href="https://github.com/Aaryan2304/geospatial-ai" target="_blank" class="github-icon-link" title="View on GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                </div>

                <!-- Project 4: Video Anomaly -->
                <div class="tech-card project-card tilt-card">
                    <span style="display: inline-block; background: rgba(16, 185, 129, 0.15); border: 1px solid #10B981; color: #10B981; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; margin-bottom: 1rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em;">Production</span>
                    <h3>Video Anomaly Detection</h3>
                                        
                    <p>Non-blocking video processing pipeline using Convolutional Autoencoders. Engineered to handle high-bitrate streams without timeout errors.</p>
                    
                    <!-- NEW METRICS BOX -->
                    <div class="project-metrics">
                        <div class="metric"><i class="fas fa-bullseye"></i> 0.92 Precision</div>
                        <div class="metric"><i class="fas fa-tachometer-alt"></i> Non-blocking Async</div>
                        <div class="metric"><i class="fas fa-chart-line"></i> Prometheus Monitoring</div>
                    </div>

                    <div class="tags">
                        <span class="tag">PyTorch</span>
                        <span class="tag">Autoencoder</span>
                        <span class="tag">MLOps</span>
                    </div>
                    <a href="https://github.com/Aaryan2304/cctv-video-anomaly-detection" target="_blank" class="github-icon-link" title="View on GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                </div>

            </div>
        </div>
    </section>

    <!-- 03 // Technical Arsenal (Skills) -->
    <section id="skills" style="margin-bottom: 8rem;">
        <div class="reveal-element">
            <p class="subtitle">04 // Stack</p>
            <h2>Technical Arsenal</h2>
            <div class="tech-card skills-card">
                
                <div class="skill-category">
                    <h4><i class="fas fa-code"></i> Languages & Frameworks</h4>
                    <ul>
                        <li>Python, MySQL</li>
                        <li>TensorFlow, PyTorch</li>
                        <li>NumPy, Pandas, Matplotlib, Scikit-learn</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h4><i class="fas fa-eye"></i> Computer Vision</h4>
                    <ul>
                        <li>YOLO, RT-DETR, SAM, VLMs</li>
                        <li>Object Detection, Segmentation, Classification, Pose/Keypoint Estimation</li>
                        <li>Geospatial AI</li>
                        <li>Multi-Object Tracking (ByteTrack, DeepSORT, Kalman Filter)</li>
                        <li>OCR (PaddleOCR, Tesseract, EasyOCR)</li>
                        <li>Homography, Feature Matching</li>
                        <li>3D Vision</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h4><i class="fas fa-database"></i> Data & Annotation</h4>
                    <ul>
                        <li>Roboflow, CVAT, Supervisely</li>
                        <li>QGIS, ArcGIS (Geospatial)</li>
                        <li>COCO, YOLO, Pascal VOC, GeoTIFF, Shapefile formats</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h4><i class="fas fa-brain"></i> AI Agents & LLMs</h4>
                    <ul>
                        <li>LangChain, LangGraph</li>
                        <li>Agentic RAG</li>
                        <li>Hugging Face Transformers</li>
                        <li>Vector DBs (Pinecone/Chroma)</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h4><i class="fas fa-tachometer-alt"></i> Optimization</h4>
                    <ul>
                        <li>ONNX, TensorRT, vLLM</li>
                        <li>INT8/INT4 Quantization</li>
                        <li>Pruning, LoRA/PEFT</li>
                        <li>Mixed-precision (AMP)</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h4><i class="fas fa-server"></i> MLOps & Backend</h4>
                    <ul>
                        <li>Docker, FastAPI</li>
                        <li>Git, Streamlit</li>
                        <li>Prometheus Monitoring</li>
                    </ul>
                </div>

            </div>
        </div>
    </section>

    <!-- 06 // Background (Education) -->
    <section id="education">
        <div class="reveal-element">
            <p class="subtitle">06 // Background</p>
            <h2>Education & Certifications</h2>
            <div class="tech-card" style="margin-bottom: 2rem;">
                <div class="experience-header">
                    <div>
                        <h3>MIT World Peace University</h3>
                        <p style="margin:0; color: var(--primary-neon);">B.Tech, Electronics & Communication Engineering - AI/ML</p>
                    </div>
                    <span class="exp-date">Jun 2021 - Jun 2025</span>
                </div>
                <p style="margin-bottom: 0;">Pune, India</p>
            </div>
            
            <div class="tech-card">
                <h3 style="margin-bottom: 1rem;">Certifications</h3>
                <ul class="tech-list" style="margin: 0;">
                    <li>AI Agents Fundamentals - HuggingFace</li>
                    <li>Google Cloud Computing Foundations - NPTEL</li>
                    <li>Computer Vision Bootcamp - OpenCV</li>
                </ul>
            </div>
        </div>
    </section>
    
    <!-- 07 // Open Source (Community) -->
    <section id="oss">
        <div class="reveal-element">
            <p class="subtitle">07 // Community</p>
            <h2>Open Source</h2>
            <div class="tech-card">
                <p style="font-size: 1.1rem; margin: 0;">
                    Active contributor to 
                    <a href="https://github.com/roboflow" target="_blank" style="color: var(--primary-neon); text-decoration: none; border-bottom: 1px solid var(--primary-neon); transition: border-color 0.3s;">Roboflow</a>, 
                    <a href="https://github.com/huggingface" target="_blank" style="color: var(--primary-neon); text-decoration: none; border-bottom: 1px solid var(--primary-neon); transition: border-color 0.3s;">HuggingFace</a>, 
                    and computer vision libraries. Contributing to open-source tools that democratize AI and make CV accessible to developers worldwide.
                </p>
            </div>
        </div>
    </section>
</div>

<!-- 6. Footer Centered -->
<footer>
    <p>Designed & Engineered by Aaryan Kurade © 2026</p>
</footer>

<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>
// --- 1. Staggered Reveal Animation ---
document.addEventListener("DOMContentLoaded", () => {
const reveals = document.querySelectorAll('.reveal-element');
const observer = new IntersectionObserver((entries) => {
entries.forEach((entry) => {
if (entry.isIntersecting) {
entry.target.classList.add('visible');
}
});
}, { threshold: 0.1, rootMargin: "0px 0px -50px 0px" });
reveals.forEach(el => observer.observe(el));
});

// --- 2. 3D Tilt Effect ---
const cards = document.querySelectorAll('.tilt-card');
cards.forEach(card => {
card.addEventListener('mousemove', (e) => {
const rect = card.getBoundingClientRect();
const x = e.clientX - rect.left;
const y = e.clientY - rect.top;

// Calculate rotation
const centerX = rect.width / 2;
const centerY = rect.height / 2;

const rotateX = ((y - centerY) / centerY) * -5;
const rotateY = ((x - centerX) / centerX) * 5;
card.style.transform = `perspective(1000px) rotateX(${rotateX}deg) rotateY(${rotateY}deg) scale3d(1.02, 1.02, 1.02)`;
});
card.addEventListener('mouseleave', () => {
card.style.transform = 'perspective(1000px) rotateX(0) rotateY(0) scale3d(1, 1, 1)';
});
});

// --- 3. Three.js "Computer Vision" LiDAR Scan ---
const initThreeJS = () => {
const container = document.getElementById('canvas-container');
const scene = new THREE.Scene();

// Fog for depth
scene.fog = new THREE.FogExp2(0x030305, 0.015);
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 5, 15);
camera.lookAt(0, 0, 0);
const renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
container.appendChild(renderer.domElement);

// --- Part A: LiDAR Terrain (Point Cloud) ---
const particlesGeometry = new THREE.BufferGeometry();
const count = 3000;

const positions = new Float32Array(count * 3);
const colors = new Float32Array(count * 3);
// Create a wavy grid of points
for (let i = 0; i < count; i++) {
const x = (Math.random() - 0.5) * 50;
const z = (Math.random() - 0.5) * 50;
const y = Math.sin(x * 0.2) * Math.cos(z * 0.2) * 1.5; // Wavy terrain
positions[i * 3] = x;
positions[i * 3 + 1] = y - 5; // Shift down
positions[i * 3 + 2] = z;
// Initial color (dark)
colors[i * 3] = 0.2;
colors[i * 3 + 1] = 0.2;
colors[i * 3 + 2] = 0.25;
}
particlesGeometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
particlesGeometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));
const particlesMaterial = new THREE.PointsMaterial({
size: 0.12,
vertexColors: true,
transparent: true,
opacity: 0.8
});
const terrain = new THREE.Points(particlesGeometry, particlesMaterial);
scene.add(terrain);

// --- Part B: Floating Tracking Rectangles (Bounding Boxes) ---
const createReticle = () => {
// Create a square shape
const geometry = new THREE.BufferGeometry();
const vertices = new Float32Array([
-1, -1, 0, 1, -1, 0,
1, -1, 0, 1, 1, 0,
1, 1, 0, -1, 1, 0,
-1, 1, 0, -1, -1, 0
]);
geometry.setAttribute('position', new THREE.BufferAttribute(vertices, 3));
const material = new THREE.LineBasicMaterial({ color: 0x3B82F6, transparent: true, opacity: 0.5 });
return new THREE.LineSegments(geometry, material);
};
const reticles = [];
for(let i=0; i<4; i++) {
const r = createReticle();
r.position.set(
(Math.random() - 0.5) * 20,
(Math.random() - 0.5) * 10,
(Math.random() - 0.5) * 10
);
r.userData = {
speed: Math.random() * 0.02 + 0.01,
dirX: Math.random() > 0.5 ? 1 : -1,
dirY: Math.random() > 0.5 ? 1 : -1
};
scene.add(r);
reticles.push(r);
}
// Mouse interaction vars
let mouseX = 0;
let mouseY = 0;
document.addEventListener('mousemove', (event) => {
mouseX = (event.clientX / window.innerWidth) * 2 - 1;
mouseY = -(event.clientY / window.innerHeight) * 2 + 1;
});
// Animation Loop
let time = 0;
const animate = () => {
requestAnimationFrame(animate);
time += 0.05;
// 1. Terrain Rotation & Scanning Effect
terrain.rotation.y += 0.001;
const positions = terrain.geometry.attributes.position.array;
const colors = terrain.geometry.attributes.color.array;

// Update colors based on "scan wave" logic
// We visualize a scan line moving across the terrain
const scanPos = Math.sin(time * 0.5) * 25; // Oscillate between -25 and 25
for (let i = 0; i < count; i++) {
const x = positions[i * 3];
// If point is near the scan line...
if (Math.abs(x - scanPos) < 3.0) {
// Highlight Neon Blue
colors[i * 3] = 0.23; // R
colors[i * 3 + 1] = 0.51; // G
colors[i * 3 + 2] = 0.96; // B
} else {
// Fade back to dark grey/blue
colors[i * 3] *= 0.95; // Decay trail
if (colors[i * 3] < 0.1) colors[i * 3] = 0.1; // Floor
colors[i * 3 + 1] *= 0.95;
if (colors[i * 3 + 1] < 0.1) colors[i * 3 + 1] = 0.1;
colors[i * 3 + 2] *= 0.95;
if (colors[i * 3 + 2] < 0.15) colors[i * 3 + 2] = 0.15;
}
}
terrain.geometry.attributes.color.needsUpdate = true;
// 2. Reticles Animation (Floating Bounding Boxes)
reticles.forEach(r => {
r.rotation.z += 0.01;
r.rotation.y += 0.01;

// Drift movement
r.position.x += r.userData.speed * r.userData.dirX;
r.position.y += r.userData.speed * r.userData.dirY;
// Boundary checks
if(Math.abs(r.position.x) > 15) r.userData.dirX *= -1;
if(Math.abs(r.position.y) > 8) r.userData.dirY *= -1;
// Slight parallax with mouse
r.position.x += (mouseX * 0.05 - r.position.x * 0.001) * 0.02;
});
renderer.render(scene, camera);
};
animate();
window.addEventListener('resize', () => {
camera.aspect = window.innerWidth / window.innerHeight;
camera.updateProjectionMatrix();
renderer.setSize(window.innerWidth, window.innerHeight);
});
};
initThreeJS();
</script>
</body>
</html>
